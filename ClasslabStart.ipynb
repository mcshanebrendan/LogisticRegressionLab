{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of X:\n",
      " [[0.65882353 0.82745098 0.95294118]\n",
      " [0.14509804 0.1254902  0.15686275]\n",
      " [0.1372549  0.13333333 0.14901961]\n",
      " [0.30980392 0.29019608 0.62352941]\n",
      " [0.21568627 0.38823529 0.13333333]]\n",
      "First 5 labels (y):\n",
      " ['blue' 'black' 'black' 'purple' 'green']\n",
      "Shape of X: (3950, 3)\n",
      "Shape of y: (3950,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import lab2rgb\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skimage.color import rgb2lab\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load CSV file\n",
    "df = pd.read_csv(\"colour-data.csv\")\n",
    "\n",
    "# Extract R, G, B columns as features\n",
    "X = df[['R', 'G', 'B']].values  \n",
    "\n",
    "# Normalize RGB values to range [0,1]\n",
    "X = X / 255.0  \n",
    "\n",
    "# Extract color labels as target variable\n",
    "y = df['Label'].values  # Change 'Label' to the correct column name from your CSV\n",
    "\n",
    "\n",
    "print(\"First 5 rows of X:\\n\", X[:5])\n",
    "print(\"First 5 labels (y):\\n\", y[:5])\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "\n",
    "\n",
    "# representative RGB colours for each label, for nice display\n",
    "COLOUR_RGB = {\n",
    "    'red': (255, 0, 0),\n",
    "    'orange': (255, 114, 0),\n",
    "    'yellow': (255, 255, 0),\n",
    "    'green': (0, 230, 0),\n",
    "    'blue': (0, 0, 255),\n",
    "    'purple': (187, 0, 187),\n",
    "    'brown': (117, 60, 0),\n",
    "    'pink': (255, 187, 187),\n",
    "    'black': (0, 0, 0),\n",
    "    'grey': (150, 150, 150),\n",
    "    'white': (255, 255, 255),\n",
    "}\n",
    "name_to_rgb = np.vectorize(COLOUR_RGB.get, otypes=[np.uint8, np.uint8, np.uint8])\n",
    "\n",
    "\n",
    "def plot_predictions(model, lum=71, resolution=256):\n",
    "    \"\"\"\n",
    "    Create a slice of LAB colour space with given luminance; predict with the model; plot the results.\n",
    "    \"\"\"\n",
    "    wid = resolution\n",
    "    hei = resolution\n",
    "    n_ticks = 5\n",
    "\n",
    "    # create a hei*wid grid of LAB colour values, with L=lum\n",
    "    ag = np.linspace(-100, 100, wid)\n",
    "    bg = np.linspace(-100, 100, hei)\n",
    "    aa, bb = np.meshgrid(ag, bg)\n",
    "    ll = lum * np.ones((hei, wid))\n",
    "    lab_grid = np.stack([ll, aa, bb], axis=2)\n",
    "\n",
    "    # convert to RGB for consistency with original input\n",
    "    X_grid = lab2rgb(lab_grid)\n",
    "\n",
    "    # predict and convert predictions to colours so we can see what's happening\n",
    "    y_grid = model.predict(X_grid.reshape((wid*hei, 3)))\n",
    "    pixels = np.stack(name_to_rgb(y_grid), axis=1) / 255\n",
    "    pixels = pixels.reshape((hei, wid, 3))\n",
    "\n",
    "    # plot input and predictions\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.suptitle('Predictions at L=%g' % (lum,))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Inputs')\n",
    "    plt.xticks(np.linspace(0, wid, n_ticks), np.linspace(-100, 100, n_ticks))\n",
    "    plt.yticks(np.linspace(0, hei, n_ticks), np.linspace(-100, 100, n_ticks))\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('B')\n",
    "    plt.imshow(X_grid.reshape((hei, wid, 3)))\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Predicted Labels')\n",
    "    plt.xticks(np.linspace(0, wid, n_ticks), np.linspace(-100, 100, n_ticks))\n",
    "    plt.yticks(np.linspace(0, hei, n_ticks), np.linspace(-100, 100, n_ticks))\n",
    "    plt.xlabel('A')\n",
    "    plt.imshow(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_remainder, y_train, y_remainder = train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_remainder, y_remainder, random_state=42, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score (RGB Model): 0.6925675675675675\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression model on RGB\n",
    "model_rgb = LogisticRegression(max_iter=1000)\n",
    "model_rgb.fit(X_train, y_train)\n",
    "\n",
    "# Print validation score\n",
    "print(\"Validation Score (RGB Model):\", model_rgb.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       black       0.70      0.87      0.77        61\n",
      "        blue       0.86      0.74      0.79        99\n",
      "       brown       0.64      0.24      0.35        29\n",
      "       green       0.73      0.96      0.83       127\n",
      "        grey       0.49      0.53      0.51        49\n",
      "      orange       0.75      0.40      0.52        15\n",
      "        pink       0.50      0.68      0.58        38\n",
      "      purple       0.72      0.80      0.76        95\n",
      "         red       0.50      0.30      0.38        50\n",
      "       white       0.00      0.00      0.00        10\n",
      "      yellow       1.00      0.32      0.48        19\n",
      "\n",
      "    accuracy                           0.69       592\n",
      "   macro avg       0.63      0.53      0.54       592\n",
      "weighted avg       0.69      0.69      0.67       592\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brend\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\brend\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\brend\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict on validation set\n",
    "y_pred = model_rgb.predict(X_valid)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makelab(X):\n",
    "    X = X.reshape(1, -1, 3)  # Reshape for skimage\n",
    "    lab = rgb2lab(X)         # Convert to LAB\n",
    "    return lab.reshape(-1, 3)  # Reshape back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score (LAB Model): 0.722972972972973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brend\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that first converts RGB â†’ LAB, then applies Logistic Regression\n",
    "model_lab = make_pipeline(\n",
    "    FunctionTransformer(makelab),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "# Train on training data\n",
    "model_lab.fit(X_train, y_train)\n",
    "\n",
    "# Print validation score for LAB model\n",
    "print(\"Validation Score (LAB Model):\", model_lab.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       black       0.81      0.84      0.82        61\n",
      "        blue       0.81      0.75      0.78        99\n",
      "       brown       0.69      0.31      0.43        29\n",
      "       green       0.85      0.92      0.88       127\n",
      "        grey       0.48      0.73      0.58        49\n",
      "      orange       0.73      0.53      0.62        15\n",
      "        pink       0.60      0.79      0.68        38\n",
      "      purple       0.76      0.79      0.77        95\n",
      "         red       0.42      0.32      0.36        50\n",
      "       white       0.00      0.00      0.00        10\n",
      "      yellow       0.86      0.63      0.73        19\n",
      "\n",
      "    accuracy                           0.72       592\n",
      "   macro avg       0.64      0.60      0.61       592\n",
      "weighted avg       0.72      0.72      0.71       592\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brend\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\brend\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\brend\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_lab = model_lab.predict(X_valid)\n",
    "print(classification_report(y_valid, y_pred_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.0001, Mean Validation Score: 0.22423146473779382\n",
      "C=0.001, Mean Validation Score: 0.22423146473779382\n",
      "C=0.01, Mean Validation Score: 0.2835443037974683\n",
      "C=0.1, Mean Validation Score: 0.532368896925859\n",
      "C=1, Mean Validation Score: 0.6433996383363473\n",
      "C=10, Mean Validation Score: 0.6871609403254973\n",
      "C=100, Mean Validation Score: 0.6933092224231465\n",
      "C=1000, Mean Validation Score: 0.6943942133815552\n"
     ]
    }
   ],
   "source": [
    "# Try different values of C (Regularization Parameter)\n",
    "for c in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    model = LogisticRegression(C=c, max_iter=1000)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(f\"C={c}, Mean Validation Score: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best model type (RGB or LAB) and best C value\n",
    "final_model = LogisticRegression(C=best_C, max_iter=1000)\n",
    "\n",
    "# Train on both training + validation set\n",
    "final_model.fit(np.vstack([X_train, X_valid]), np.hstack([y_train, y_valid]))\n",
    "\n",
    "# Print test score\n",
    "print(\"Final Test Score:\", final_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = final_model.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN with k=5\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Print validation score\n",
    "print(\"Validation Score (KNN Model):\", knn_model.score(X_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
